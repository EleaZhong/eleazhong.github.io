<!DOCTYPE html>
<html lang="en"><meta charset="utf-8"><meta name="generator" content="Hugo 0.72.0" /><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover">
<meta name="color-scheme" content="light dark">
<meta name="supported-color-schemes" content="light dark"><title>Finding the genre of a song with Deep Learning — A.I. Odyssey part. 1&nbsp;&ndash;&nbsp;Waterbuffalo Posts</title><link rel="stylesheet" href="/css/core.min.c208fa0587ec5fc82784f905103d462872daed7adcb50f71dbbd39818c904fcb5f0df067adf68e8049d68401a71f436e.css" integrity="sha384-wgj6BYfsX8gnhPkFED1GKHLa7XrctQ9x2705gYyQT8tfDfBnrfaOgEnWhAGnH0Nu"><meta name="twitter:card" content="summary" />
<meta name="twitter:title" content="Finding the genre of a song with Deep Learning — A.I. Odyssey part. 1" /><meta name="twitter:image" content="https://hackernoon.com/hn-images/1*_slyjgv6vspbmd_w-lffvq.gif" />
<link rel="icon" type="image/png" sizes="32x32" href="/favicon.png">
<link href="/al.css" rel="stylesheet"><body><section id="header">
    <div class="header wrap"><span class="header left-side"><a class="site home" href="/"><img class="site logo" src="/favicon.png" alt /><span class="site name">Waterbuffalo Posts</span></a></span>
        <span class="header right-side"><div class="nav wrap"><nav class="nav"><a class="nav item" href="/categories/">Categories</a><a class="nav item" href="/tags/">Tags</a><a class="nav item" href="/about">About</a><a class="nav item" href="https://gohugo%2eio/"target="_blank">News</a><a class="nav item" href="/AI">AI</a><a class="nav item" href="/Crypto">Crypto</a><a class="nav item" href="/Coding">Coding</a><a class="nav item" href="/Startups">Startups</a><a class="nav item" href="/Coronavirus">Coronavirus</a><a class="nav item" href="/Learn">Learn</a><a class="nav item" href="/Future">Future</a><a class="nav item" href="/login">Login</a></nav></div></span></div></section><section id="content"><div class="article-container"><section class="article header">
    <h1 class="article title">Finding the genre of a song with Deep Learning — A.I. Odyssey part. 1</h1><p class="article date">Saturday, June 8, 2019<span class="reading-time"> • 8 minutes to read</span></p><style type="text/css">

.resp-sharing-button__link,
.resp-sharing-button__icon {
  display: inline-block
}

.resp-sharing-button__link {
  text-decoration: none;
  color: #fff;
  margin-top: 0.5em;
}

.resp-sharing-button {
  border-radius: 5px;
  transition: 25ms ease-out;
  padding: 0.1em 0.5em 0.2em 0.5em;
  font-family: Helvetica Neue,Helvetica,Arial,sans-serif
}

.resp-sharing-button__icon svg {
  width: 1em;
  height: 1em;
  margin-right: 0.4em;
  vertical-align: top
}

.resp-sharing-button--small svg {
  margin: 0;
  vertical-align: middle
}

 
.resp-sharing-button__icon {
  stroke: #fff;
  fill: none
}

 
.resp-sharing-button__icon--solid,
.resp-sharing-button__icon--solidcircle {
  fill: #fff;
  stroke: none
}

.resp-sharing-button--twitter {
  background-color: #55acee
}

.resp-sharing-button--twitter:hover {
  background-color: #2795e9
}

.resp-sharing-button--pinterest {
  background-color: #bd081c
}

.resp-sharing-button--pinterest:hover {
  background-color: #8c0615
}

.resp-sharing-button--facebook {
  background-color: #3b5998
}

.resp-sharing-button--facebook:hover {
  background-color: #2d4373
}

.resp-sharing-button--tumblr {
  background-color: #35465C
}

.resp-sharing-button--tumblr:hover {
  background-color: #222d3c
}

.resp-sharing-button--reddit {
  background-color: #5f99cf
}

.resp-sharing-button--reddit:hover {
  background-color: #3a80c1
}

.resp-sharing-button--google {
  background-color: #dd4b39
}

.resp-sharing-button--google:hover {
  background-color: #c23321
}

.resp-sharing-button--linkedin {
  background-color: #0077b5
}

.resp-sharing-button--linkedin:hover {
  background-color: #046293
}

.resp-sharing-button--email {
  background-color: #777
}

.resp-sharing-button--email:hover {
  background-color: #5e5e5e
}

.resp-sharing-button--xing {
  background-color: #1a7576
}

.resp-sharing-button--xing:hover {
  background-color: #114c4c
}

.resp-sharing-button--whatsapp {
  background-color: #25D366
}

.resp-sharing-button--whatsapp:hover {
  background-color: #1da851
}

.resp-sharing-button--hackernews {
background-color: #FF6600
}
.resp-sharing-button--hackernews:hover, .resp-sharing-button--hackernews:focus {   background-color: #FB6200 }

.resp-sharing-button--vk {
  background-color: #507299
}

.resp-sharing-button--vk:hover {
  background-color: #43648c
}

.resp-sharing-button--twitter {
  background-color: #55acee;
  border-color: #55acee;
}

.resp-sharing-button--twitter:hover,
.resp-sharing-button--twitter:active {
  background-color: #2795e9;
  border-color: #2795e9;
}

.resp-sharing-button--email {
  background-color: #777777;
  border-color: #777777;
}

.resp-sharing-button--email:hover,
.resp-sharing-button--email:active {
  background-color: #5e5e5e;
  border-color: #5e5e5e;
}

.resp-sharing-button--reddit {
  background-color: #5f99cf;
  border-color: #5f99cf;
}

.resp-sharing-button--reddit:hover,
.resp-sharing-button--reddit:active {
  background-color: #3a80c1;
  border-color: #3a80c1;
}

.resp-sharing-button--hackernews {
  background-color: #FF6600;
  border-color: #FF6600;
}

.resp-sharing-button--hackernews:hover
.resp-sharing-button--hackernews:active {
  background-color: #FB6200;
  border-color: #FB6200;
}



</style>

<div class="social-links">

<a class="resp-sharing-button__link" href="https://twitter.com/intent/tweet/?text=Super%20fast%20and%20easy%20Social%20Media%20Sharing%20Buttons.%20No%20JavaScript.%20No%20tracking.&amp;url=http%3A%2F%2Fsharingbuttons.io" target="_blank" rel="noopener" aria-label="">
  <div class="resp-sharing-button resp-sharing-button--twitter resp-sharing-button--small"><div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solidcircle">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 0C5.38 0 0 5.38 0 12s5.38 12 12 12 12-5.38 12-12S18.62 0 12 0zm5.26 9.38v.34c0 3.48-2.64 7.5-7.48 7.5-1.48 0-2.87-.44-4.03-1.2 1.37.17 2.77-.2 3.9-1.08-1.16-.02-2.13-.78-2.46-1.83.38.1.8.07 1.17-.03-1.2-.24-2.1-1.3-2.1-2.58v-.05c.35.2.75.32 1.18.33-.7-.47-1.17-1.28-1.17-2.2 0-.47.13-.92.36-1.3C7.94 8.85 9.88 9.9 12.06 10c-.04-.2-.06-.4-.06-.6 0-1.46 1.18-2.63 2.63-2.63.76 0 1.44.3 1.92.82.6-.12 1.95-.27 1.95-.27-.35.53-.72 1.66-1.24 2.04z"/></svg>
    </div>
  </div>
</a>


<a class="resp-sharing-button__link" href="mailto:?subject=Super%20fast%20and%20easy%20Social%20Media%20Sharing%20Buttons.%20No%20JavaScript.%20No%20tracking.&amp;body=http%3A%2F%2Fsharingbuttons.io" target="_self" rel="noopener" aria-label="">
  <div class="resp-sharing-button resp-sharing-button--email resp-sharing-button--small"><div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solidcircle">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 0C5.38 0 0 5.38 0 12s5.38 12 12 12 12-5.38 12-12S18.62 0 12 0zm8 16c0 1.1-.9 2-2 2H6c-1.1 0-2-.9-2-2V8c0-1.1.9-2 2-2h12c1.1 0 2 .9 2 2v8z"/><path d="M17.9 8.18c-.2-.2-.5-.24-.72-.07L12 12.38 6.82 8.1c-.22-.16-.53-.13-.7.08s-.15.53.06.7l3.62 2.97-3.57 2.23c-.23.14-.3.45-.15.7.1.14.25.22.42.22.1 0 .18-.02.27-.08l3.85-2.4 1.06.87c.1.04.2.1.32.1s.23-.06.32-.1l1.06-.9 3.86 2.4c.08.06.17.1.26.1.17 0 .33-.1.42-.25.15-.24.08-.55-.15-.7l-3.57-2.22 3.62-2.96c.2-.2.24-.5.07-.72z"/></svg>
    </div>
  </div>
</a>


<a class="resp-sharing-button__link" href="https://reddit.com/submit/?url=http%3A%2F%2Fsharingbuttons.io&amp;resubmit=true&amp;title=Super%20fast%20and%20easy%20Social%20Media%20Sharing%20Buttons.%20No%20JavaScript.%20No%20tracking." target="_blank" rel="noopener" aria-label="">
  <div class="resp-sharing-button resp-sharing-button--reddit resp-sharing-button--small"><div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solidcircle">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><circle cx="9.391" cy="13.392" r=".978"/><path d="M14.057 15.814c-1.14.66-2.987.655-4.122-.004-.238-.138-.545-.058-.684.182-.13.24-.05.545.19.685.72.417 1.63.646 2.568.646.93 0 1.84-.228 2.558-.642.24-.13.32-.44.185-.68-.14-.24-.445-.32-.683-.18zM5 12.086c0 .41.23.78.568.978.27-.662.735-1.264 1.353-1.774-.2-.207-.48-.334-.79-.334-.62 0-1.13.507-1.13 1.13z"/><path d="M12 0C5.383 0 0 5.383 0 12s5.383 12 12 12 12-5.383 12-12S18.617 0 12 0zm6.673 14.055c.01.104.022.208.022.314 0 2.61-3.004 4.73-6.695 4.73s-6.695-2.126-6.695-4.74c0-.105.013-.21.022-.313C4.537 13.73 4 12.97 4 12.08c0-1.173.956-2.13 2.13-2.13.63 0 1.218.29 1.618.757 1.04-.607 2.345-.99 3.77-1.063.057-.803.308-2.33 1.388-2.95.633-.366 1.417-.323 2.322.085.302-.81 1.076-1.397 1.99-1.397 1.174 0 2.13.96 2.13 2.13 0 1.177-.956 2.133-2.13 2.133-1.065 0-1.942-.79-2.098-1.81-.734-.4-1.315-.506-1.716-.276-.6.346-.818 1.395-.88 2.087 1.407.08 2.697.46 3.728 1.065.4-.468.987-.756 1.617-.756 1.17 0 2.13.953 2.13 2.13 0 .89-.54 1.65-1.33 1.97z"/><circle cx="14.609" cy="13.391" r=".978"/><path d="M17.87 10.956c-.302 0-.583.128-.79.334.616.51 1.082 1.112 1.352 1.774.34-.197.568-.566.568-.978 0-.623-.507-1.13-1.13-1.13z"/></svg>
    </div>
  </div>
</a>


<a class="resp-sharing-button__link" href="https://news.ycombinator.com/submitlink?u=http%3A%2F%2Fsharingbuttons.io&amp;t=Super%20fast%20and%20easy%20Social%20Media%20Sharing%20Buttons.%20No%20JavaScript.%20No%20tracking." target="_blank" rel="noopener" aria-label="">
  <div class="resp-sharing-button resp-sharing-button--hackernews resp-sharing-button--small"><div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solidcircle">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 256"><path fill-rule="evenodd" d="M128 256c70.692 0 128-57.308 128-128C256 57.308 198.692 0 128 0 57.308 0 0 57.308 0 128c0 70.692 57.308 128 128 128zm-9.06-113.686L75 60h20.08l25.85 52.093c.397.927.86 1.888 1.39 2.883.53.994.995 2.02 1.393 3.08.265.4.463.764.596 1.095.13.334.262.63.395.898.662 1.325 1.26 2.618 1.79 3.877.53 1.26.993 2.42 1.39 3.48 1.06-2.254 2.22-4.673 3.48-7.258 1.26-2.585 2.552-5.27 3.877-8.052L161.49 60h18.69l-44.34 83.308v53.087h-16.9v-54.08z"/></svg>
    </div>
  </div>
</a>

</div>
</section><article class="article markdown-body"><p><img  src="https://hackernoon.com/hn-images/1*_SLyjgV6vspBMD_w-lfFvQ.gif"
        alt="img"/></p>
<p>A step-by-step guide to make your computer a music expert.</p>
<p>One of the things we, humans, are particularly good at is classifying songs. In just a few seconds we can tell whether we’re listening to Classical music, Rap, Blues or EDM. However, as simple as this task is for us, millions of people still live with unclassifed digital music libraries.</p>
<p>The average library is estimated to have about 7,160 songs. If it takes 3 seconds to classify a song (either by listening or because you already know), a quick back-of-the-envelope calculation gives around 6 hours to classify them all.</p>
<p>If you add the time it takes to manually label the song, this can easily go up to 10+ hours of manual work. <strong>No one wants to do that.</strong></p>
<p><img  src="https://hackernoon.com/hn-images/1*nU9v9AQFJm0YwBv2-5DkXQ.jpeg"
        alt="img"/></p>
<p>In this post, we’ll see how we can use <strong>Deep Learning</strong> to help us in this labour-intensive task.</p>
<p>Here’s a general overview of what we will do:</p>
<ul>
<li>Extract a simplified representation of each song in the library</li>
<li>Train a deep neural network to classify the songs</li>
<li>Use the classifier to fill in the mising genres of our library</li>
</ul>
<h4 id="the-data">The data</h4>
<p>First of all, we’re going to need a dataset. For that I have started with my own iTunes library — which is already labelled due to my slightly obsessive passion for order. Although it is not as diverse, complete or even as big as other datasets we could find, it is a good start. Note that I have only used 2,000 songs as it already represents a lot of data.</p>
<h4 id="refining-the-dataset">Refining the dataset</h4>
<p>The first observation is that there are too many genres and <strong>subgenres</strong>, or to put it differently, genres with too few examples. This needs to be corrected, either by removing the examples from the dataset, or by assigning them to a broader genre. We don’t really need this <em>Concertos</em> genre, <em>Classical</em> will do the trick.</p>
<p><img  src="https://hackernoon.com/hn-images/1*3-5BrEnYL723NrvLkiLK_w.png"
        alt="img"/>Creating super genres</p>
<h4 id="too-much-informationwaaaaaay-to-much">Too much information — Waaaaaay to much</h4>
<p>Once we have a decent number of genres, with enough songs each, we can start to extract the important information from the data. A song is nothing but a very, very long series of values. The classic sampling frequency is 44100Hz — there are 44100 values stored for every second of audio, and twice as much for stereo.</p>
<p>This means that a <strong>3 minute</strong> long stereo song contains <strong>7,938,000 samples</strong>. That’s a lot of information, and we need to reduce this to a more manageable level if we want to do anything with it. We can start by <em>discarding the stereo channel</em> as it contains highly redundant information.</p>
<p><img  src="https://hackernoon.com/hn-images/1*xbiQh8B_KJaMFU193I9mwA.gif"
        alt="img"/>DeepMind —<a href="https://deepmind.com/blog/wavenet-generative-model-raw-audio/?ref=hackernoon.com"target="_blank"> WaveNet</a></p>
<p>We will use <em>Fourier’s Transform</em> to convert our audio data to the frequency domain. This allows for a much more simple and compact representation of the data, which we will export as a <strong>spectrogram</strong>. This process will give us a PNG file containing the evolution of all the frequencies of our song through time.</p>
<p>The 44100Hz sampling rate we talked about earlier allows us to reconstruct frequencies up to 22050Hz — see <a href="https://en.wikipedia.org/wiki/Nyquist%e2%80%93Shannon_sampling_theorem?ref=hackernoon.com#Aliasing"target="_blank">Nyquist-Shannon sampling theorem</a> — but now that the frequencies are extracted, we can use a much lower resolution. Here, we’ll use 50 pixel per second (20ms per pixel), which is more than enough to be sure to use all the information we need.</p>
<p><strong>NB:</strong> If you know a genre characterized by ~20ms frequency variations, you got me.</p>
<p>Here’s what our song looks like after the process (12.8s sample shown here).</p>
<p><img  src="https://hackernoon.com/hn-images/1*Fd_IRjlygBvJy5ivbsfarw.png"
        alt="img"/>Spectrogram of an extract of the song</p>
<p><strong>Time</strong> is on the x axis, and <strong>frequency</strong> on the y axis. The highest frequencies are at the top and the lowest at the bottom. The scaled amplitude of the frequency is shown in greyscale, with white being the maximum and black the minimum.</p>
<p>I have used use a spectrogram with 128 frequency levels, because it contains all the relevant information of the song — we can easily distinguish different notes/frequencies.</p>
<h4 id="further-processing">Further processing</h4>
<p>The next thing we have to do is to deal with the length of the songs. There are two approaches for this problem. The first one would be to use a <em>recurrent neural network</em> with wich we would feed each column of the image in order. Instead, I have chosen to exploit even further the fact that humans are able to classify songs with <strong>short extracts</strong>.</p>
<blockquote>
<p>If we can classify songs by ear in under 3 seconds, why couldn’t machines do the same ?</p>
</blockquote>
<p>We can create <em>fixed length</em> slices of the spectrogram, and consider them as independent samples representing the genre. We can use <strong>square slices</strong> for convenience, which means that we will cut down the spectrogram into 128x128 pixel slices. This represents 2.56s worth of data in each slice.</p>
<p><img  src="https://hackernoon.com/hn-images/1*WsJNdWQCU7QFpWK4DbVSig.png"
        alt="img"/>Sliced spectrogram</p>
<p>At this point, we could use <strong>data augmentation</strong> to expand the dataset even more (we won’t here because we aready have a lot of data). We could for instance add random noise to the images, or slightly stretch them horizontally and then crop them.</p>
<p>However, we have to make sure that we do not break the patterns of the data. We can’t <em>rotate</em> the images, nor <em>flip</em> them horizontally because sounds are not symmetrical.</p>
<p><em>E.g,</em> see those <em>white fading lines</em>? These are decaying sounds which cannot be reversed.</p>
<p><img  src="https://hackernoon.com/hn-images/1*ZG5ScpOX5MejoejUgHOTbg.png"
        alt="img"/>Decaying sound</p>
<h4 id="choice-of-the-modellets-build-a-classifier">Choice of the model — Let’s build a classifier!</h4>
<p>After we have sliced all our songs into square spectral images, we have a dataset containing tens of thousands of samples for each genre. We can now train a <strong>Deep Convolutional Neural Network</strong> to classify these samples. For this purpose, I have used Tensorflow’s wrapper TFLearn.</p>
<p><img  src="https://hackernoon.com/hn-images/1*FQyTMv3f7m2WHFWz5gCy9g.png"
        alt="img"/>Convolutional neural network</p>
<h4 id="implementation-details">Implementation details</h4>
<ul>
<li><em>Dataset split: T</em>raining (70%), validation (20%), testing (10%)</li>
<li><em>Model</em>: Convolutional neural network.</li>
<li><em>Layers</em>: Kernels of size 2x2 with stride of 2</li>
<li><em>Optimizer</em>: <em>RMSProp.</em></li>
<li><em>Activation function:</em> ELU (Exponential Linear Unit), because of the <a href="https://arxiv.org/pdf/1511.07289.pdf?ref=hackernoon.com"target="_blank">performance it has shown when compared to ReLUs</a></li>
<li><em>Initialization</em>: Xavier for the weights matrices in all layers.</li>
<li><em>Regularization</em>: Dropout with probability 0.5</li>
</ul>
<h4 id="resultsdoes-this-thing-work">Results — Does this thing work?</h4>
<p>With 2,000 songs split between 6 genres — <em>Hardcore, Dubstep, Electro, Classical, Soundtrack and Rap</em>, and using more than 12,000 128x128 spectrogram slices in total, the model reached *<strong>90% accuracy*</strong> on the validation set. This is pretty good, especially considering that we are processing the songs tiny bits at a time. Note that <strong>this is not the final accuracy</strong> we’ll have on classifying whole songs (it will be even better). We’re only talking <em>slices</em> here.</p>
<h4 id="time-to-classify-some-files">Time to classify some files!</h4>
<p>So far, we have converted our songs from stereo to mono and created a spectrogram, which we sliced into small bits. We then used these slices to train a deep neural network. We can now use the model to classify a new song that we have <em>never seen</em>.</p>
<p>We start off by generating the spectrogram the same way we did with the training data. Because of the slicing, we cannot predict the class of the song in one go. We have to slice the new song, and then put together the predicted classes for all the slices.</p>
<p>To do that, we will use a <strong>voting system</strong>. Each sample of the track will “vote” for a genre, and we choose the genre with the most votes. This will increase our accuracy as we’ll get rid of many classifications errors with this ensemble learning-<em>esque</em> method.</p>
<p><strong>NB:</strong> a 3 minute long track has about 70 slices.</p>
<p><img  src="https://hackernoon.com/hn-images/1*flj7wvpYCYFKbtxHcmC7Nw.png"
        alt="img"/>Voting system</p>
<p>With this pipeline, we can now classify the unlabelled songs from our library. We could simply run the voting system on all the songs for which we need a genre, and take the word of the classifier. This would give good results but we might want to improve our voting system.</p>
<p><img  src="https://hackernoon.com/hn-images/1*Q9ShITwmtB8kCOJ6EnC8vg.png"
        alt="img"/>Full classification pipeline</p>
<h4 id="a-better-voting-system">A better voting system</h4>
<p>The last layer of the classifier we have built is a <strong>softmax</strong> <em>layer.</em> This means that it doesn’t really output the detected genre, but rather the probabilities of each. This is what we call the classification <strong>confidence</strong>.</p>
<p><img  src="https://hackernoon.com/hn-images/1*bJ0Gc9GxHmjVwh9lLfzaQA.png"
        alt="img"/>Classification confidence</p>
<p>We can use this to improve our voting system. For instance, we could reject votes from slices with low confidence. If there is no clear winner, we reject the vote.</p>
<blockquote>
<p>It’s better to say “I don’t know” than to give a answer we’re not sure of.</p>
</blockquote>
<p><img  src="https://hackernoon.com/hn-images/1*BGo9AGDNp0aoCC5W3PBzaA.png"
        alt="img"/>Classification rejected because of the low confidence</p>
<p>Similarly, we could leave unlabelled the songs for which no genre received more than a certain fraction -<em>70%?-</em> of the votes. This way, we will avoid mislabeling songs, which we can still label later by hand.</p>
<p><img  src="https://hackernoon.com/hn-images/1*RAChvpql8BEqbVSDkqP26w.png"
        alt="img"/>Track left unlabeled because of low voting system confidence</p>
<h3 id="conclusions">Conclusions</h3>
<p>In this post, we have seen how we could extract important information from redundant and high dimensional data structure — <em>tracks</em>. We have taken advantage of short patterns in the data which allowed us to classify 2.56 second long extracts. Finally, we have used our model to fill in the blanks in a digital library.</p>
<blockquote>
<p>*<strong>If you like Artificial Intelligence,*</strong> <a href="http://eepurl.com/cATXvT?ref=hackernoon.com"target="_blank">*<strong>subscribe to the newsletter*</strong></a> *<strong>to receive updates on articles and much more!*</strong></p>
</blockquote>
<p>*<strong>(Psst!*</strong> <a href="https://medium.com/@juliendespois/talk-to-you-computer-with-you-eyes-and-deep-learning-a-i-odyssey-part-2-7d3405ab8be1?ref=hackernoon.com#.j6htbas27"target="_blank">*<strong>part. 2*</strong></a> *<strong>is out!)*</strong></p>
<p>You can play with the code here:</p>
<p><a href="https://github.com/despoisj/DeepAudioClassification?ref=hackernoon.com"target="_blank">despoisj/DeepAudioClassification</a></p>
<p>If you want to go further on audio classification, there are other approaches which yield impressive results, such as <a href="https://www.toptal.com/algorithms/shazam-it-music-processing-fingerprinting-and-recognition?ref=hackernoon.com"target="_blank">Shazam’s fingerprinting technique</a> or <a href="http://blog.themusio.com/2016/11/04/dilated-causal-convolutions-for-audio-and-text-generation/?ref=hackernoon.com"target="_blank">dilated convolutions</a>.</p>
<p>Thanks for reading this post, stay tuned for more !</p>
</article></div>
<div class="article bottom"><section class="article navigation"><p><a class="link" href="/news/hackernoon1/"><span class="iconfont icon-article"></span>Last Article:&nbsp;&nbsp;What’s really wrong with node_modules and why this is your fault</a></p></section><section class="article discussion"><div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "xiee" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a></section></div></section><section id="footer"><div class="footer-wrap">
    <p class="copyright">Waterbuffalo Posts</p>
    <p class="powerby" style="font-size:7px;"><span>Powered by </span><a href="https://gohugo.io" 
        target="_blank">Hugo</a><span> and </span><a href="https://themes.gohugo.io/hugo-notepadium/" 
        target="_blank">Notepadium</a></p>
</div></section><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/&#43;DiW/UqRcLbRjq" crossorigin="anonymous"><script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l&#43;B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd&#43;qj&#43;o24G5ZU2zJz" crossorigin="anonymous"></script><script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
            onload="renderMathInElement(document.body);"></script><script src="/js/hljs.min.0799348a91dce12c6be4a73f943cfe78f181f4e6f6ec35c4af0fca1de377879f77cfab03c30f03a174d675737b5a9314.js" integrity="sha384-B5k0ipHc4Sxr5Kc/lDz&#43;ePGB9Ob27DXErw/KHeN3h593z6sDww8DoXTWdXN7WpMU"></script><script>hljs.initHighlightingOnLoad();</script></body>

</html>